{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2022320",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph langchain langchain_openai prometheus-api-client python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, TypedDict\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "from langgraph.graph import StateGraph, END\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a505f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "#  请在这里填入您的 Azure OpenAI 凭证\n",
    "# =================================================================\n",
    "AZURE_OPENAI_ENDPOINT = \"\"  # 例如: \"https://myhealthagentai.openai.azure.com/\"\n",
    "AZURE_OPENAI_API_KEY = \"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt-5-prometheus\"\n",
    "# =================================================================\n",
    "\n",
    "\n",
    "# --- 初始化 Azure OpenAI LLM ---\n",
    "print(\"正在初始化 Azure OpenAI LLM...\")\n",
    "try:\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=\"2025-01-01-preview\",\n",
    "        azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "        temperature=1\n",
    "    )\n",
    "    # 简单测试一下LLM是否工作正常\n",
    "    llm.invoke(\"你好\")\n",
    "    print(\"Azure OpenAI LLM 初始化并测试成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM 初始化失败，请检查您的凭证和网络连接。错误信息: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 初始化 Prometheus 连接 ---\n",
    "PROMETHEUS_URL = \"http://xxxxx:9090\"\n",
    "try:\n",
    "    prom_connect = PrometheusConnect(url=PROMETHEUS_URL, disable_ssl=True)\n",
    "    # 检查是否能连接到 Prometheus\n",
    "    if prom_connect.check_prometheus_connection():\n",
    "        print(f\"成功连接到 Prometheus at {PROMETHEUS_URL}\")\n",
    "    else:\n",
    "        print(f\"无法连接到 Prometheus，请确保 'kubectl port-forward' 命令正在运行。\")\n",
    "except Exception as e:\n",
    "    print(f\"连接 Prometheus 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterHealthState(TypedDict):\n",
    "    \"\"\"\n",
    "    定义了在整个工作流中传递的数据结构 (状态)。\n",
    "    \"\"\"\n",
    "    cluster_name: str\n",
    "    metrics_to_query: List[str]\n",
    "    prometheus_url: str\n",
    "    raw_metrics_data: Dict[str, Any]\n",
    "    analysis_result: str\n",
    "    assessment_result: str\n",
    "    final_report: str\n",
    "\n",
    "print(\"Agent 状态定义完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metrics_node(state: ClusterHealthState) -> Dict[str, Any]:\n",
    "    print(\"--- 正在执行: [数据获取代理] ---\")\n",
    "    metrics_to_query = state['metrics_to_query']\n",
    "    collected_data = {}\n",
    "    for metric_name in metrics_to_query:\n",
    "        try:\n",
    "            data = prom_connect.custom_query(query=metric_name)\n",
    "            collected_data[metric_name] = data\n",
    "        except Exception as e:\n",
    "            collected_data[metric_name] = f\"查询失败: {e}\"\n",
    "    print(\"--- [数据获取代理] 执行完毕 ---\")\n",
    "    return {\"raw_metrics_data\": collected_data}\n",
    "\n",
    "def analyze_data_node(state: ClusterHealthState) -> Dict[str, Any]:\n",
    "    print(\"--- 正在执行: [数据分析代理] (可能需要一些时间) ---\")\n",
    "    raw_data = state['raw_metrics_data']\n",
    "    prompt = f\"\"\"\n",
    "    你是一个资深的网站可靠性工程师(SRE)。你的任务是分析以下来自 Prometheus 的原始监控数据。\n",
    "    请将这些复杂的 JSON 数据转换成简洁、易于理解的摘要。\n",
    "    对于每个指标，请识别出：\n",
    "    1.  涉及哪些实例 (instance) 或节点 (node)。\n",
    "    2.  每个实例的当前值是多少。\n",
    "    3.  如果数据是一个范围，请指出最大值、最小值和平均值。\n",
    "    4.  识别任何看起来可能是异常或值得关注的数值（例如，一个节点负载远高于其他节点）。\n",
    "    原始数据:\n",
    "    ```json\n",
    "    {raw_data}\n",
    "    ```\n",
    "    请生成你的分析摘要：\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    analysis = response.content\n",
    "    print(\"--- [数据分析代理] 执行完毕 ---\")\n",
    "    return {\"analysis_result\": analysis}\n",
    "\n",
    "def assess_health_node(state: ClusterHealthState) -> Dict[str, Any]:\n",
    "    print(\"--- 正在执行: [健康评估代理] ---\")\n",
    "    analysis = state['analysis_result']\n",
    "    health_rules = \"\"\"\n",
    "    - 1分钟平均负载 (node_load1):\n",
    "        - 0-2: 健康 (Healthy)\n",
    "        - 2-5: 警告 (Warning) - 负载较高，需要关注。\n",
    "        - >5: 严重 (Critical) - 负载过高，可能影响性能。\n",
    "    - 节点可用内存百分比 (node_memory_available_percent):\n",
    "        - >20%: 健康 (Healthy)\n",
    "        - 10%-20%: 警告 (Warning) - 内存资源开始紧张。\n",
    "        - <10%: 严重 (Critical) - 内存即将耗尽，有 OOM (Out of Memory) 风险。\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    你是一位经验丰富的 DevOps 专家。根据以下数据分析摘要和健康评估规则，对集群的健康状况进行评估。\n",
    "    你的任务是:\n",
    "    1.  对每个节点和每个关键指标，根据规则判断其状态（健康、警告、严重）。\n",
    "    2.  给出一个整体的集群健康评估（例如：整体健康，但有潜在风险）。\n",
    "    3.  明确指出哪些节点或指标需要特别关注。\n",
    "    \n",
    "    健康评估规则:\n",
    "    {health_rules}\n",
    "    \n",
    "    数据分析摘要:\n",
    "    {analysis}\n",
    "    \n",
    "    请生成你的健康评估结论：\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    assessment = response.content\n",
    "    print(\"--- [健康评估代理] 执行完毕 ---\")\n",
    "    return {\"assessment_result\": assessment}\n",
    "\n",
    "def generate_report_node(state: ClusterHealthState) -> Dict[str, Any]:\n",
    "    print(\"--- 正在执行: [报告生成代理] ---\")\n",
    "    cluster_name = state['cluster_name']\n",
    "    analysis = state['analysis_result']\n",
    "    assessment = state['assessment_result']\n",
    "    prompt = f\"\"\"\n",
    "    你是一个AI运维助手，你的任务是为集群 \"{cluster_name}\" 生成一份清晰、专业的健康评估报告。\n",
    "    请使用 Markdown 格式。报告应包含以下部分：\n",
    "    1.  **集群健康评估报告**:\n",
    "        -   **1. 集群健康状况**: 给出整体评估。\n",
    "        -   **2. 异常点分析**: 详细描述异常点和可能原因。\n",
    "        -   **3. 风险识别**: 指出潜在风险。\n",
    "        -   **4. 优化建议**: 给出具体、可操作的建议。\n",
    "    2.  **总结**: 对报告进行简要总结。\n",
    "    请严格按照这个结构，并基于以下信息来撰写报告：\n",
    "    [数据分析摘要]\n",
    "    {analysis}\n",
    "    [健康评估结论]\n",
    "    {assessment}\n",
    "    现在，请生成最终的 Markdown 格式报告：\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    report = response.content\n",
    "    print(\"--- [报告生成代理] 执行完毕 ---\")\n",
    "    return {\"final_report\": report}\n",
    "\n",
    "print(\"所有 Agent 功能节点定义完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(ClusterHealthState)\n",
    "\n",
    "# 添加节点\n",
    "workflow.add_node(\"fetch_metrics\", fetch_metrics_node)\n",
    "workflow.add_node(\"analyze_data\", analyze_data_node)\n",
    "workflow.add_node(\"assess_health\", assess_health_node)\n",
    "workflow.add_node(\"generate_report\", generate_report_node)\n",
    "\n",
    "# 定义工作流的执行顺序\n",
    "workflow.set_entry_point(\"fetch_metrics\")\n",
    "workflow.add_edge(\"fetch_metrics\", \"analyze_data\")\n",
    "workflow.add_edge(\"analyze_data\", \"assess_health\")\n",
    "workflow.add_edge(\"assess_health\", \"generate_report\")\n",
    "workflow.add_edge(\"generate_report\", END)\n",
    "\n",
    "# 编译成可执行的应用\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"LangGraph 工作流构建并编译完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164285b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义我们要分析的指标\n",
    "node_memory_available_percent = '(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100'\n",
    "\n",
    "# 设置初始输入\n",
    "inputs = {\n",
    "    \"cluster_name\": \"MyHealthAgentCluster\",\n",
    "    \"prometheus_url\": PROMETHEUS_URL,\n",
    "    \"metrics_to_query\": [\n",
    "        \"node_load1\",  # 1分钟平均负载\n",
    "        node_memory_available_percent, # 节点可用内存百分比\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 运行工作流！\n",
    "# 这个过程会依次调用我们定义的每个节点，并打印执行信息\n",
    "print(\"开始执行工作流...\")\n",
    "final_state = app.invoke(inputs)\n",
    "print(\"\\n工作流执行完毕！最终报告已生成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ddc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从最终状态中获取报告内容\n",
    "final_report_markdown = final_state['final_report']\n",
    "\n",
    "# 使用 IPython.display.Markdown 在 Notebook 中漂亮地展示报告\n",
    "print(\"========= 集群健康评估报告 (预览) =========\")\n",
    "display(Markdown(final_report_markdown))\n",
    "\n",
    "# 将报告保存到文件中\n",
    "report_filename = \"cluster_health_report.md\"\n",
    "with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_report_markdown)\n",
    "\n",
    "print(f\"\\n报告已成功保存到文件: {report_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
